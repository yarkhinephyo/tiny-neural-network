{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d093dd3",
   "metadata": {},
   "source": [
    "## Tiny Neural Network\n",
    "\n",
    "Building a simple yet functional feedforward Neural Network from the ground up\n",
    "\n",
    "References:\n",
    "- https://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "- https://www.freecodecamp.org/news/building-a-neural-network-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ea43282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e316913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\"\n",
    "    Sigmoid Activation\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def activation_deriv(z):\n",
    "    \"\"\"\n",
    "    Derivative of Sigmod w.r.t output z\n",
    "    \"\"\"\n",
    "    return z * (1 - z)\n",
    "\n",
    "def cost_function(z, y):\n",
    "    \"\"\"\n",
    "    Cost function of binary classification\n",
    "    j = -y * ln(y_hat) - (1-y) * ln(1 - y_hat)\n",
    "    \"\"\"\n",
    "    return -y * np.log(z) - (1-y) * np.log(1-z)\n",
    "\n",
    "def cost_function_deriv(z, y):\n",
    "    \"\"\"\n",
    "    Cost function derivative w.r.t output z\n",
    "    last_error = (z - y) / (z * (1 - z)) where z == y_hat\n",
    "    \"\"\"\n",
    "    return (z - y) / (z * (1 - z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df367a8c",
   "metadata": {},
   "source": [
    "### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cea20004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e-04],\n",
       "       [0.e+00],\n",
       "       [1.e+00],\n",
       "       [1.e+00]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feedforward Neural Network\n",
    "> One-Layer (3 Neurons)\n",
    "> No bias term\n",
    "\n",
    "Each layer consists of:\n",
    "    v1 = z0 * w1\n",
    "    z1 = sigmoid(v1)\n",
    "\"\"\"\n",
    "X = np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1]\n",
    "])\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "max_iter = 30000\n",
    "\n",
    "w1 = 2 * np.random.random((X.shape[1],1)) - 1\n",
    "z0 = X\n",
    "\n",
    "for iter_ in range(max_iter):\n",
    "    z1 = activation(np.dot(z0, w1)) # Shape (4 x 1)\n",
    "    l1_error = cost_function_deriv(z1, y) # Shape (4 x 1)\n",
    "    l1_dzdv = l1_error * activation_deriv(z1) # Shape (4 x 1)\n",
    "    w1 -= np.dot(z0.T, l1_dzdv) # Shape (3, 1)\n",
    "\n",
    "np.round(z1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df71881",
   "metadata": {},
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4fadf6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00],\n",
       "       [9.999e-01],\n",
       "       [9.999e-01],\n",
       "       [1.000e-04]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feedforward Neural Network\n",
    "> Two-Layer (3 Neurons, 4 Neurons)\n",
    "> Has bias term\n",
    "\n",
    "Cost function derivative w.r.t next layer:\n",
    "    l1_error = l2_dzdv * w2\n",
    "\n",
    "Each layer consists of:\n",
    "    v1 = z0 * w1 + b1\n",
    "    z1 = sigmoid(v1)\n",
    "\"\"\"\n",
    "\n",
    "X = np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1]\n",
    "])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "max_iter = 30000\n",
    "\n",
    "w1 = 2 * np.random.random((X.shape[1],4)) - 1\n",
    "b1 = np.ones((1,4))\n",
    "w2 = 2 * np.random.random((4,1)) - 1\n",
    "b2 = np.ones((1,1))\n",
    "z0 = X\n",
    "\n",
    "for iter_ in range(max_iter):\n",
    "    z1 = activation(np.dot(z0, w1) + b1) # Shape (4 x 4)\n",
    "    z2 = activation(np.dot(z1, w2) + b2) # Shape (4 x 1)\n",
    "    \n",
    "    l2_error = cost_function_deriv(z2, y) # Shape (4 x 1)\n",
    "    l2_dzdv = l2_error * activation_deriv(z2) # Shape (4 x 1)\n",
    "    l1_error = np.dot(l2_dzdv, w2.T) # Shape (4 x 4)\n",
    "    l1_dzdv = l1_error * activation_deriv(z1) # Shape (4 x 4)\n",
    "    \n",
    "    w2 -= np.dot(z1.T, l2_dzdv) # Shape (4 x 1)\n",
    "    b2 -= np.sum(l2_dzdv, axis=0, keepdims=True)\n",
    "    w1 -= np.dot(z0.T, l1_dzdv) # Shape (3 x 4)\n",
    "    b1 -= np.sum(l1_dzdv, axis=0, keepdims=True)\n",
    "\n",
    "np.round(z2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1118e",
   "metadata": {},
   "source": [
    "### Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec0b7c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last iteration: 2001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0015],\n",
       "       [0.9981],\n",
       "       [0.9982],\n",
       "       [0.0017]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feedforward Neural Network\n",
    "> Two-Layer (3 Neurons, 4 Neurons)\n",
    "> Has bias term\n",
    "> Has early stopping\n",
    "> Has learning rate scheduler\n",
    "\"\"\"\n",
    "\n",
    "X = np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1]\n",
    "])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "X_val, y_val = X.copy(), y.copy()\n",
    "lr_scheduler = lambda i: 1 / np.power(i, 0.05)\n",
    "tol = 0.0001\n",
    "n_iter_no_change = 100\n",
    "count_iter_no_change = 0\n",
    "prev_lowest_val_error = float('inf')\n",
    "max_iter = 30000\n",
    "\n",
    "w1 = 2 * np.random.random((X.shape[1],4)) - 1\n",
    "b1 = np.ones((1,4))\n",
    "w2 = 2 * np.random.random((4,1)) - 1\n",
    "b2 = np.ones((1,1))\n",
    "z0 = X\n",
    "z0_val = X_val\n",
    "\n",
    "for iter_ in range(1, max_iter):\n",
    "    z1 = activation(np.dot(z0, w1) + b1) # Shape (4 x 4)\n",
    "    z2 = activation(np.dot(z1, w2) + b2) # Shape (4 x 1)\n",
    "    \n",
    "    l2_error = cost_function_deriv(z2, y) # Shape (4 x 1)    \n",
    "    l2_dzdv = l2_error * activation_deriv(z2) # Shape (4 x 1)\n",
    "    l1_error = np.dot(l2_dzdv, w2.T) # Shape (4 x 4)\n",
    "    l1_dzdv = l1_error * activation_deriv(z1) # Shape (4 x 4)\n",
    "    \n",
    "    w2 -= lr_scheduler(iter_) * np.dot(z1.T, l2_dzdv) # Shape (4 x 1)\n",
    "    b2 -= lr_scheduler(iter_) * np.sum(l2_dzdv, axis=0, keepdims=True)\n",
    "    w1 -= lr_scheduler(iter_) * np.dot(z0.T, l1_dzdv) # Shape (3 x 4)\n",
    "    b1 -= lr_scheduler(iter_) * np.sum(l1_dzdv, axis=0, keepdims=True)\n",
    "    \n",
    "    # Early stopping based on validation error score\n",
    "    z1_val = activation(np.dot(z0_val, w1) + b1) # Shape (4 x 4)\n",
    "    z2_val = activation(np.dot(z1_val, w2) + b2) # Shape (4 x 1)\n",
    "    val_error =  cost_function(z2_val, y_val) # Shape (4 x 1)\n",
    "    val_error_mean = np.abs(np.mean(val_error))\n",
    "    if val_error_mean + tol < prev_lowest_val_error:\n",
    "        count_iter_no_change = 0\n",
    "        prev_lowest_val_error = val_error_mean\n",
    "    else:\n",
    "        count_iter_no_change += 1\n",
    "        if count_iter_no_change >= n_iter_no_change:\n",
    "            print(\"Last iteration: \" + str(iter_))\n",
    "            break\n",
    "\n",
    "np.round(z2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyFeedForwardNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, dims, cost_func, activation_func, early_stopping, max_iter, tol):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
